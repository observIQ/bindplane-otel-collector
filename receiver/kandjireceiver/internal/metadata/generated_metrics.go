// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/filter"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver"
)

// AttributeReason specifies the value reason attribute.
type AttributeReason int

const (
	_ AttributeReason = iota
	AttributeReasonHTTPError
	AttributeReasonJSONError
	AttributeReasonTimeout
	AttributeReasonRateLimit
)

// String returns the string representation of the AttributeReason.
func (av AttributeReason) String() string {
	switch av {
	case AttributeReasonHTTPError:
		return "http_error"
	case AttributeReasonJSONError:
		return "json_error"
	case AttributeReasonTimeout:
		return "timeout"
	case AttributeReasonRateLimit:
		return "rate_limit"
	}
	return ""
}

// MapAttributeReason is a helper map of string to AttributeReason attribute value.
var MapAttributeReason = map[string]AttributeReason{
	"http_error": AttributeReasonHTTPError,
	"json_error": AttributeReasonJSONError,
	"timeout":    AttributeReasonTimeout,
	"rate_limit": AttributeReasonRateLimit,
}

// AttributeStatus specifies the value status attribute.
type AttributeStatus int

const (
	_ AttributeStatus = iota
	AttributeStatusSuccess
	AttributeStatusError
)

// String returns the string representation of the AttributeStatus.
func (av AttributeStatus) String() string {
	switch av {
	case AttributeStatusSuccess:
		return "success"
	case AttributeStatusError:
		return "error"
	}
	return ""
}

// MapAttributeStatus is a helper map of string to AttributeStatus attribute value.
var MapAttributeStatus = map[string]AttributeStatus{
	"success": AttributeStatusSuccess,
	"error":   AttributeStatusError,
}

var MetricsInfo = metricsInfo{
	KandjiAPICalls: metricInfo{
		Name: "kandji.api.calls",
	},
	KandjiAPIErrors: metricInfo{
		Name: "kandji.api.errors",
	},
	KandjiAPILatency: metricInfo{
		Name: "kandji.api.latency",
	},
	KandjiDataBytes: metricInfo{
		Name: "kandji.data.bytes",
	},
	KandjiPaginationPages: metricInfo{
		Name: "kandji.pagination.pages",
	},
	KandjiRecordsReceived: metricInfo{
		Name: "kandji.records.received",
	},
	KandjiScrapeDuration: metricInfo{
		Name: "kandji.scrape.duration",
	},
}

type metricsInfo struct {
	KandjiAPICalls        metricInfo
	KandjiAPIErrors       metricInfo
	KandjiAPILatency      metricInfo
	KandjiDataBytes       metricInfo
	KandjiPaginationPages metricInfo
	KandjiRecordsReceived metricInfo
	KandjiScrapeDuration  metricInfo
}

type metricInfo struct {
	Name string
}

type metricKandjiAPICalls struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills kandji.api.calls metric with initial data.
func (m *metricKandjiAPICalls) init() {
	m.data.SetName("kandji.api.calls")
	m.data.SetDescription("Total number of Kandji API calls performed by the receiver.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricKandjiAPICalls) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, endpointAttributeValue string, statusAttributeValue string, httpStatusAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("endpoint", endpointAttributeValue)
	dp.Attributes().PutStr("status", statusAttributeValue)
	dp.Attributes().PutStr("http_status", httpStatusAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricKandjiAPICalls) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricKandjiAPICalls) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricKandjiAPICalls(cfg MetricConfig) metricKandjiAPICalls {
	m := metricKandjiAPICalls{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricKandjiAPIErrors struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills kandji.api.errors metric with initial data.
func (m *metricKandjiAPIErrors) init() {
	m.data.SetName("kandji.api.errors")
	m.data.SetDescription("Number of Kandji API requests that failed.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricKandjiAPIErrors) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, endpointAttributeValue string, reasonAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("endpoint", endpointAttributeValue)
	dp.Attributes().PutStr("reason", reasonAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricKandjiAPIErrors) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricKandjiAPIErrors) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricKandjiAPIErrors(cfg MetricConfig) metricKandjiAPIErrors {
	m := metricKandjiAPIErrors{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricKandjiAPILatency struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills kandji.api.latency metric with initial data.
func (m *metricKandjiAPILatency) init() {
	m.data.SetName("kandji.api.latency")
	m.data.SetDescription("Kandji API call duration per endpoint.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricKandjiAPILatency) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, endpointAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("endpoint", endpointAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricKandjiAPILatency) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricKandjiAPILatency) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricKandjiAPILatency(cfg MetricConfig) metricKandjiAPILatency {
	m := metricKandjiAPILatency{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricKandjiDataBytes struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills kandji.data.bytes metric with initial data.
func (m *metricKandjiDataBytes) init() {
	m.data.SetName("kandji.data.bytes")
	m.data.SetDescription("Total number of bytes returned in Kandji API responses.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricKandjiDataBytes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, endpointAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("endpoint", endpointAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricKandjiDataBytes) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricKandjiDataBytes) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricKandjiDataBytes(cfg MetricConfig) metricKandjiDataBytes {
	m := metricKandjiDataBytes{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricKandjiPaginationPages struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills kandji.pagination.pages metric with initial data.
func (m *metricKandjiPaginationPages) init() {
	m.data.SetName("kandji.pagination.pages")
	m.data.SetDescription("Number of pagination pages processed for Kandji API calls.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricKandjiPaginationPages) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, endpointAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("endpoint", endpointAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricKandjiPaginationPages) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricKandjiPaginationPages) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricKandjiPaginationPages(cfg MetricConfig) metricKandjiPaginationPages {
	m := metricKandjiPaginationPages{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricKandjiRecordsReceived struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills kandji.records.received metric with initial data.
func (m *metricKandjiRecordsReceived) init() {
	m.data.SetName("kandji.records.received")
	m.data.SetDescription("Number of records returned from Kandji API responses.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityDelta)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricKandjiRecordsReceived) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, endpointAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("endpoint", endpointAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricKandjiRecordsReceived) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricKandjiRecordsReceived) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricKandjiRecordsReceived(cfg MetricConfig) metricKandjiRecordsReceived {
	m := metricKandjiRecordsReceived{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricKandjiScrapeDuration struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills kandji.scrape.duration metric with initial data.
func (m *metricKandjiScrapeDuration) init() {
	m.data.SetName("kandji.scrape.duration")
	m.data.SetDescription("Duration of the entire Kandji scrape cycle.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
}

func (m *metricKandjiScrapeDuration) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricKandjiScrapeDuration) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricKandjiScrapeDuration) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricKandjiScrapeDuration(cfg MetricConfig) metricKandjiScrapeDuration {
	m := metricKandjiScrapeDuration{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user config.
type MetricsBuilder struct {
	config                         MetricsBuilderConfig // config of the metrics builder.
	startTime                      pcommon.Timestamp    // start time that will be applied to all recorded data points.
	metricsCapacity                int                  // maximum observed number of metrics per resource.
	metricsBuffer                  pmetric.Metrics      // accumulates metrics data before emitting.
	buildInfo                      component.BuildInfo  // contains version information.
	resourceAttributeIncludeFilter map[string]filter.Filter
	resourceAttributeExcludeFilter map[string]filter.Filter
	metricKandjiAPICalls           metricKandjiAPICalls
	metricKandjiAPIErrors          metricKandjiAPIErrors
	metricKandjiAPILatency         metricKandjiAPILatency
	metricKandjiDataBytes          metricKandjiDataBytes
	metricKandjiPaginationPages    metricKandjiPaginationPages
	metricKandjiRecordsReceived    metricKandjiRecordsReceived
	metricKandjiScrapeDuration     metricKandjiScrapeDuration
}

// MetricBuilderOption applies changes to default metrics builder.
type MetricBuilderOption interface {
	apply(*MetricsBuilder)
}

type metricBuilderOptionFunc func(mb *MetricsBuilder)

func (mbof metricBuilderOptionFunc) apply(mb *MetricsBuilder) {
	mbof(mb)
}

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) MetricBuilderOption {
	return metricBuilderOptionFunc(func(mb *MetricsBuilder) {
		mb.startTime = startTime
	})
}
func NewMetricsBuilder(mbc MetricsBuilderConfig, settings receiver.Settings, options ...MetricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		config:                         mbc,
		startTime:                      pcommon.NewTimestampFromTime(time.Now()),
		metricsBuffer:                  pmetric.NewMetrics(),
		buildInfo:                      settings.BuildInfo,
		metricKandjiAPICalls:           newMetricKandjiAPICalls(mbc.Metrics.KandjiAPICalls),
		metricKandjiAPIErrors:          newMetricKandjiAPIErrors(mbc.Metrics.KandjiAPIErrors),
		metricKandjiAPILatency:         newMetricKandjiAPILatency(mbc.Metrics.KandjiAPILatency),
		metricKandjiDataBytes:          newMetricKandjiDataBytes(mbc.Metrics.KandjiDataBytes),
		metricKandjiPaginationPages:    newMetricKandjiPaginationPages(mbc.Metrics.KandjiPaginationPages),
		metricKandjiRecordsReceived:    newMetricKandjiRecordsReceived(mbc.Metrics.KandjiRecordsReceived),
		metricKandjiScrapeDuration:     newMetricKandjiScrapeDuration(mbc.Metrics.KandjiScrapeDuration),
		resourceAttributeIncludeFilter: make(map[string]filter.Filter),
		resourceAttributeExcludeFilter: make(map[string]filter.Filter),
	}
	if mbc.ResourceAttributes.KandjiRegion.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["kandji.region"] = filter.CreateFilter(mbc.ResourceAttributes.KandjiRegion.MetricsInclude)
	}
	if mbc.ResourceAttributes.KandjiRegion.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["kandji.region"] = filter.CreateFilter(mbc.ResourceAttributes.KandjiRegion.MetricsExclude)
	}
	if mbc.ResourceAttributes.KandjiSubdomain.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["kandji.subdomain"] = filter.CreateFilter(mbc.ResourceAttributes.KandjiSubdomain.MetricsInclude)
	}
	if mbc.ResourceAttributes.KandjiSubdomain.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["kandji.subdomain"] = filter.CreateFilter(mbc.ResourceAttributes.KandjiSubdomain.MetricsExclude)
	}

	for _, op := range options {
		op.apply(mb)
	}
	return mb
}

// NewResourceBuilder returns a new resource builder that should be used to build a resource associated with for the emitted metrics.
func (mb *MetricsBuilder) NewResourceBuilder() *ResourceBuilder {
	return NewResourceBuilder(mb.config.ResourceAttributes)
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (mb *MetricsBuilder) updateCapacity(rm pmetric.ResourceMetrics) {
	if mb.metricsCapacity < rm.ScopeMetrics().At(0).Metrics().Len() {
		mb.metricsCapacity = rm.ScopeMetrics().At(0).Metrics().Len()
	}
}

// ResourceMetricsOption applies changes to provided resource metrics.
type ResourceMetricsOption interface {
	apply(pmetric.ResourceMetrics)
}

type resourceMetricsOptionFunc func(pmetric.ResourceMetrics)

func (rmof resourceMetricsOptionFunc) apply(rm pmetric.ResourceMetrics) {
	rmof(rm)
}

// WithResource sets the provided resource on the emitted ResourceMetrics.
// It's recommended to use ResourceBuilder to create the resource.
func WithResource(res pcommon.Resource) ResourceMetricsOption {
	return resourceMetricsOptionFunc(func(rm pmetric.ResourceMetrics) {
		res.CopyTo(rm.Resource())
	})
}

// WithStartTimeOverride overrides start time for all the resource metrics data points.
// This option should be only used if different start time has to be set on metrics coming from different resources.
func WithStartTimeOverride(start pcommon.Timestamp) ResourceMetricsOption {
	return resourceMetricsOptionFunc(func(rm pmetric.ResourceMetrics) {
		var dps pmetric.NumberDataPointSlice
		metrics := rm.ScopeMetrics().At(0).Metrics()
		for i := 0; i < metrics.Len(); i++ {
			switch metrics.At(i).Type() {
			case pmetric.MetricTypeGauge:
				dps = metrics.At(i).Gauge().DataPoints()
			case pmetric.MetricTypeSum:
				dps = metrics.At(i).Sum().DataPoints()
			}
			for j := 0; j < dps.Len(); j++ {
				dps.At(j).SetStartTimestamp(start)
			}
		}
	})
}

// EmitForResource saves all the generated metrics under a new resource and updates the internal state to be ready for
// recording another set of data points as part of another resource. This function can be helpful when one scraper
// needs to emit metrics from several resources. Otherwise calling this function is not required,
// just `Emit` function can be called instead.
// Resource attributes should be provided as ResourceMetricsOption arguments.
func (mb *MetricsBuilder) EmitForResource(options ...ResourceMetricsOption) {
	rm := pmetric.NewResourceMetrics()
	ils := rm.ScopeMetrics().AppendEmpty()
	ils.Scope().SetName(ScopeName)
	ils.Scope().SetVersion(mb.buildInfo.Version)
	ils.Metrics().EnsureCapacity(mb.metricsCapacity)
	mb.metricKandjiAPICalls.emit(ils.Metrics())
	mb.metricKandjiAPIErrors.emit(ils.Metrics())
	mb.metricKandjiAPILatency.emit(ils.Metrics())
	mb.metricKandjiDataBytes.emit(ils.Metrics())
	mb.metricKandjiPaginationPages.emit(ils.Metrics())
	mb.metricKandjiRecordsReceived.emit(ils.Metrics())
	mb.metricKandjiScrapeDuration.emit(ils.Metrics())

	for _, op := range options {
		op.apply(rm)
	}
	for attr, filter := range mb.resourceAttributeIncludeFilter {
		if val, ok := rm.Resource().Attributes().Get(attr); ok && !filter.Matches(val.AsString()) {
			return
		}
	}
	for attr, filter := range mb.resourceAttributeExcludeFilter {
		if val, ok := rm.Resource().Attributes().Get(attr); ok && filter.Matches(val.AsString()) {
			return
		}
	}

	if ils.Metrics().Len() > 0 {
		mb.updateCapacity(rm)
		rm.MoveTo(mb.metricsBuffer.ResourceMetrics().AppendEmpty())
	}
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user config, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit(options ...ResourceMetricsOption) pmetric.Metrics {
	mb.EmitForResource(options...)
	metrics := mb.metricsBuffer
	mb.metricsBuffer = pmetric.NewMetrics()
	return metrics
}

// RecordKandjiAPICallsDataPoint adds a data point to kandji.api.calls metric.
func (mb *MetricsBuilder) RecordKandjiAPICallsDataPoint(ts pcommon.Timestamp, val int64, endpointAttributeValue string, statusAttributeValue AttributeStatus, httpStatusAttributeValue string) {
	mb.metricKandjiAPICalls.recordDataPoint(mb.startTime, ts, val, endpointAttributeValue, statusAttributeValue.String(), httpStatusAttributeValue)
}

// RecordKandjiAPIErrorsDataPoint adds a data point to kandji.api.errors metric.
func (mb *MetricsBuilder) RecordKandjiAPIErrorsDataPoint(ts pcommon.Timestamp, val int64, endpointAttributeValue string, reasonAttributeValue AttributeReason) {
	mb.metricKandjiAPIErrors.recordDataPoint(mb.startTime, ts, val, endpointAttributeValue, reasonAttributeValue.String())
}

// RecordKandjiAPILatencyDataPoint adds a data point to kandji.api.latency metric.
func (mb *MetricsBuilder) RecordKandjiAPILatencyDataPoint(ts pcommon.Timestamp, val float64, endpointAttributeValue string) {
	mb.metricKandjiAPILatency.recordDataPoint(mb.startTime, ts, val, endpointAttributeValue)
}

// RecordKandjiDataBytesDataPoint adds a data point to kandji.data.bytes metric.
func (mb *MetricsBuilder) RecordKandjiDataBytesDataPoint(ts pcommon.Timestamp, val int64, endpointAttributeValue string) {
	mb.metricKandjiDataBytes.recordDataPoint(mb.startTime, ts, val, endpointAttributeValue)
}

// RecordKandjiPaginationPagesDataPoint adds a data point to kandji.pagination.pages metric.
func (mb *MetricsBuilder) RecordKandjiPaginationPagesDataPoint(ts pcommon.Timestamp, val int64, endpointAttributeValue string) {
	mb.metricKandjiPaginationPages.recordDataPoint(mb.startTime, ts, val, endpointAttributeValue)
}

// RecordKandjiRecordsReceivedDataPoint adds a data point to kandji.records.received metric.
func (mb *MetricsBuilder) RecordKandjiRecordsReceivedDataPoint(ts pcommon.Timestamp, val int64, endpointAttributeValue string) {
	mb.metricKandjiRecordsReceived.recordDataPoint(mb.startTime, ts, val, endpointAttributeValue)
}

// RecordKandjiScrapeDurationDataPoint adds a data point to kandji.scrape.duration metric.
func (mb *MetricsBuilder) RecordKandjiScrapeDurationDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricKandjiScrapeDuration.recordDataPoint(mb.startTime, ts, val)
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...MetricBuilderOption) {
	mb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op.apply(mb)
	}
}
